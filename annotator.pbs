#!/bin/bash

# Your job will use 21 nodes, 588 cores, and 3528gb of memory total.
#PBS -q standard
#PBS -l select=21:ncpus=28:mem=168gb:pcmem=6gb

### Specify a name for the job
#PBS -N wikiparse

### Specify the group name
#PBS -W group_list=msurdeanu

### Used if job requires partial node only
#PBS -l place=free:shared

### CPUtime required in hhh:mm:ss.
### Leading 0's can be omitted e.g 48:0:0 sets 48 hours
#PBS -l cput=2940:00:00

### Walltime is how long your job will run
#PBS -l walltime=05:00:00

### Set pvmem to maximum per node memory
#PBS -l pvmem=168gb



# print start time
date

DATA_DIR=extracted

# get input dir based on worker index
INPUT_DIR=$(find $DATA_DIR -type d -not -path $DATA_DIR | sort | sed "${PBS_ARRAY_INDEX}q;d")
echo "INPUT_DIR=$INPUT_DIR"

# make output dir based on input dir
# if input dir is `extracted/AA` then the output dir should be `serialized/AA`
OUTPUT_DIR=serialized/$(basename $INPUT_DIR)
echo "OUTPUT_DIR=$OUTPUT_DIR"

# parse documents
java -Xmx4g -XX:MaxMetaspaceSize=1g -cp wikiparse-assembly-0.1.0-SNAPSHOT.jar org.clulab.wikiparse.ParseDocuments $INPUT_DIR $OUTPUT_DIR

# print end time
date
